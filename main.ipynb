{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "id": "KmnOPlm1_Zdd"
            },
            "outputs": [],
            "source": [
                "import networkx as nx\n",
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import random\n",
                "import time\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "id": "7_A_3AvUxW08"
            },
            "outputs": [],
            "source": [
                "def exact_netx(graph):\n",
                "  start = time.time()\n",
                "  t = sum(nx.triangles(graph).values())/3\n",
                "  end = time.time()\n",
                "  return {\"triangles\": t, \"time\": end - start}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "id": "huHhqhPQN86t"
            },
            "outputs": [],
            "source": [
                "def exact_trace(graph):\n",
                "  start = time.time()\n",
                "  adj_matrix = nx.adjacency_matrix(graph, dtype = np.float64)\n",
                "  adj_matrix_cubed = adj_matrix @ adj_matrix @ adj_matrix\n",
                "  t = adj_matrix_cubed.trace()/6\n",
                "  end = time.time()\n",
                "  return {\"triangles\": t, \"time\": end - start}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "id": "FtTYYA63qt6P"
            },
            "outputs": [],
            "source": [
                "def uniform_sampling(graph, sample_size):\n",
                "  start = time.time()\n",
                "  nodes = list(graph.nodes)\n",
                "  n = len(nodes)\n",
                "  node_sample = random.sample(nodes, sample_size)\n",
                "  sample_t = 0\n",
                "  for node in node_sample:\n",
                "    sample_t += nx.triangles(graph, node)\n",
                "  sample_t /= 3\n",
                "  t = sample_t*n/sample_size\n",
                "  end = time.time()\n",
                "  return {\"triangles\": t, \"time\": end - start}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "id": "NCJYKqJxChh5"
            },
            "outputs": [],
            "source": [
                "def random_sampling_with_degrees(graph, sample_size):\n",
                "  start = time.time()\n",
                "  nodes = []\n",
                "  degrees = []\n",
                "  sum_of_degrees=0\n",
                "  for node in graph:\n",
                "    nodes.append(node)\n",
                "    degree=graph.degree(node)\n",
                "    degrees.append(degree)\n",
                "    sum_of_degrees+=degree\n",
                "  node_sample = random.choices(nodes, weights = degrees, k = sample_size)\n",
                "  sample_t = 0\n",
                "  for node in node_sample:\n",
                "    sample_t += nx.triangles(graph, node)/graph.degree(node)\n",
                "  t = sample_t*sum_of_degrees/3\n",
                "  end = time.time()\n",
                "  return {\"triangles\": t, \"time\": end - start}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "def hutchplusplus(graph, queries):\n",
                "    start = time.time()\n",
                "    #to fix\n",
                "    #fast operations\n",
                "    #A.A.A.S\n",
                "    adj = nx.adjacency_matrix(graph, dtype = np.float64)\n",
                "    d = adj.shape[0]\n",
                "    S = np.random.choice([1, -1], size = (d, queries/3))\n",
                "    G = np.random.choice([1, -1], size = (d, queries/3))\n",
                "    Q, R = np.linalg.qr(A @ S)\n",
                "    trace = np.trace(np.transpose(Q) @ A @ Q) + 3/queries*(np.trace(np.transpose(G) @ (np.eye(d) - Q @ np.transpose(Q)) @ A @ (np.eye(d) - Q @ np.transpose(Q)) @ G))\n",
                "    t = trace/6\n",
                "    end = time.time()\n",
                "    return {\"triangles\": t, \"time\": end - start}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# def lanczos(A, m):\n",
                "#     n = A.shape[0]\n",
                "#     v = [np.random.rand(n)]\n",
                "#     w_prime = [A @ v[0]]\n",
                "#     alpha = [w_prime[0] * v[0]]\n",
                "#     beta = []\n",
                "#     w = [w_prime[0] - alpha[0] @ v[0]]\n",
                "#     for j in range(2, m + 1):\n",
                "#         beta_j = np.linalg.norm(w[-1])\n",
                "#         beta.push(beta_j)\n",
                "#         if beta_j != 0:\n",
                "#             v_j = w[-1]/beta_j\n",
                "#         else:\n",
                "#             v_j = #TODO\n",
                "#         v.push(v_j)\n",
                "#         w_prime.push(A @ v[-1])\n",
                "#         alpha.push(w_prime[-1]*v[-1])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "# def eigenTriangle(graph, sample_size, tol):\n",
                "#   adj_matrix = nx.adjacency_matrix(graph, dtype = np.float64)\n",
                "#   nodes = list(graph.nodes)\n",
                "#   n = len(nodes)\n",
                "#   node_sample = random.sample(nodes, sample_size)\n",
                "#   for node in node_sample:\n",
                "#     lambda_1 = lanczos(A, 1)\n",
                "#     eigen = lambda_1\n",
                "#     i = 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 363
                },
                "id": "XrnWGrP0wsFt",
                "outputId": "54b1b649-671f-4d58-9309-ca178f24dc5c"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Exact NetworkX Triangles: 1612010.0, Time: 0.46515679359436035s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 201\n",
                        "Trial 2 for uniform_sampling with Sample Size: 201\n",
                        "Trial 3 for uniform_sampling with Sample Size: 201\n",
                        "Trial 4 for uniform_sampling with Sample Size: 201\n",
                        "Trial 5 for uniform_sampling with Sample Size: 201\n",
                        "Trial 6 for uniform_sampling with Sample Size: 201\n",
                        "Trial 7 for uniform_sampling with Sample Size: 201\n",
                        "Trial 8 for uniform_sampling with Sample Size: 201\n",
                        "Trial 9 for uniform_sampling with Sample Size: 201\n",
                        "Trial 10 for uniform_sampling with Sample Size: 201\n",
                        "uniform_sampling with sample size: 201: average accuracy: 0.1315481980753445, average time: 0.16481661796569824s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 403\n",
                        "Trial 2 for uniform_sampling with Sample Size: 403\n",
                        "Trial 3 for uniform_sampling with Sample Size: 403\n",
                        "Trial 4 for uniform_sampling with Sample Size: 403\n",
                        "Trial 5 for uniform_sampling with Sample Size: 403\n",
                        "Trial 6 for uniform_sampling with Sample Size: 403\n",
                        "Trial 7 for uniform_sampling with Sample Size: 403\n",
                        "Trial 8 for uniform_sampling with Sample Size: 403\n",
                        "Trial 9 for uniform_sampling with Sample Size: 403\n",
                        "Trial 10 for uniform_sampling with Sample Size: 403\n",
                        "uniform_sampling with sample size: 403: average accuracy: 0.07074719805469294, average time: 0.40008537769317626s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 605\n",
                        "Trial 2 for uniform_sampling with Sample Size: 605\n",
                        "Trial 3 for uniform_sampling with Sample Size: 605\n",
                        "Trial 4 for uniform_sampling with Sample Size: 605\n",
                        "Trial 5 for uniform_sampling with Sample Size: 605\n",
                        "Trial 6 for uniform_sampling with Sample Size: 605\n",
                        "Trial 7 for uniform_sampling with Sample Size: 605\n",
                        "Trial 8 for uniform_sampling with Sample Size: 605\n",
                        "Trial 9 for uniform_sampling with Sample Size: 605\n",
                        "Trial 10 for uniform_sampling with Sample Size: 605\n",
                        "uniform_sampling with sample size: 605: average accuracy: 0.06029768724817876, average time: 0.46116943359375s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 807\n",
                        "Trial 2 for uniform_sampling with Sample Size: 807\n",
                        "Trial 3 for uniform_sampling with Sample Size: 807\n",
                        "Trial 4 for uniform_sampling with Sample Size: 807\n",
                        "Trial 5 for uniform_sampling with Sample Size: 807\n",
                        "Trial 6 for uniform_sampling with Sample Size: 807\n",
                        "Trial 7 for uniform_sampling with Sample Size: 807\n",
                        "Trial 8 for uniform_sampling with Sample Size: 807\n",
                        "Trial 9 for uniform_sampling with Sample Size: 807\n",
                        "Trial 10 for uniform_sampling with Sample Size: 807\n",
                        "uniform_sampling with sample size: 807: average accuracy: 0.039934876636870696, average time: 0.630516767501831s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 2 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 3 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 4 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 5 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 6 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 7 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 8 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 9 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 10 for uniform_sampling with Sample Size: 1009\n",
                        "uniform_sampling with sample size: 1009: average accuracy: 0.03938293665089212, average time: 0.7430790901184082s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 2 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 3 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 4 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 5 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 6 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 7 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 8 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 9 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 10 for uniform_sampling with Sample Size: 1211\n",
                        "uniform_sampling with sample size: 1211: average accuracy: 0.04751156154825748, average time: 0.9620682001113892s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 2 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 3 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 4 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 5 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 6 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 7 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 8 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 9 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 10 for uniform_sampling with Sample Size: 1413\n",
                        "uniform_sampling with sample size: 1413: average accuracy: 0.043626075062573, average time: 1.0631184577941895s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 2 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 3 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 4 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 5 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 6 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 7 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 8 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 9 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 10 for uniform_sampling with Sample Size: 1615\n",
                        "uniform_sampling with sample size: 1615: average accuracy: 0.03656847185294228, average time: 1.4233473300933839s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 2 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 3 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 4 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 5 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 6 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 7 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 8 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 9 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 10 for uniform_sampling with Sample Size: 1817\n",
                        "uniform_sampling with sample size: 1817: average accuracy: 0.04326762662685253, average time: 2.1512490272521974s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 2 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 3 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 4 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 5 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 6 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 7 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 8 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 9 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 10 for uniform_sampling with Sample Size: 2019\n",
                        "uniform_sampling with sample size: 2019: average accuracy: 0.03318050717897507, average time: 1.7894462108612061s\n",
                        "Accuracies: [('uniform_sampling', 201, 0.17111835380204704), ('uniform_sampling', 201, 0.18594400079593262), ('uniform_sampling', 201, 0.20418935279989894), ('uniform_sampling', 201, 0.1853092985598575), ('uniform_sampling', 201, 0.1543431009871044), ('uniform_sampling', 201, 0.1483216595068425), ('uniform_sampling', 201, 0.13933775315103547), ('uniform_sampling', 201, 0.1332683208410237), ('uniform_sampling', 201, 0.13688661601506172), ('uniform_sampling', 201, 0.1315481980753445), ('uniform_sampling', 403, 0.014595294155954956), ('uniform_sampling', 403, 0.02941295940974168), ('uniform_sampling', 403, 0.025085656881225316), ('uniform_sampling', 403, 0.02521722157936195), ('uniform_sampling', 403, 0.04115323250631585), ('uniform_sampling', 403, 0.05275611744895436), ('uniform_sampling', 403, 0.04819713706901433), ('uniform_sampling', 403, 0.07110066125132919), ('uniform_sampling', 403, 0.06799057169712437), ('uniform_sampling', 403, 0.07074719805469294), ('uniform_sampling', 605, 0.11043791828223015), ('uniform_sampling', 605, 0.07961078620546672), ('uniform_sampling', 605, 0.06406210968449756), ('uniform_sampling', 605, 0.053955982917003376), ('uniform_sampling', 605, 0.04487001722931572), ('uniform_sampling', 605, 0.05343738334557816), ('uniform_sampling', 605, 0.056228492971835985), ('uniform_sampling', 605, 0.05396797011612029), ('uniform_sampling', 605, 0.05941342668799243), ('uniform_sampling', 605, 0.06029768724817876), ('uniform_sampling', 807, 0.059811896360215874), ('uniform_sampling', 807, 0.08992772872131255), ('uniform_sampling', 807, 0.061043717143694776), ('uniform_sampling', 807, 0.05994526458550352), ('uniform_sampling', 807, 0.048385321568862626), ('uniform_sampling', 807, 0.045849379896844365), ('uniform_sampling', 807, 0.039551528374715705), ('uniform_sampling', 807, 0.040101241770707924), ('uniform_sampling', 807, 0.0442914602211161), ('uniform_sampling', 807, 0.039934876636870696), ('uniform_sampling', 1009, 0.01099776127707675), ('uniform_sampling', 1009, 0.019264809918796196), ('uniform_sampling', 1009, 0.05012859613780535), ('uniform_sampling', 1009, 0.043843086973187874), ('uniform_sampling', 1009, 0.044049235505274995), ('uniform_sampling', 1009, 0.04136876655744217), ('uniform_sampling', 1009, 0.049122143691210575), ('uniform_sampling', 1009, 0.045680565281426846), ('uniform_sampling', 1009, 0.042189286367839605), ('uniform_sampling', 1009, 0.03938293665089212), ('uniform_sampling', 1211, 0.10214954656532332), ('uniform_sampling', 1211, 0.08262545321683926), ('uniform_sampling', 1211, 0.057697511777333794), ('uniform_sampling', 1211, 0.0476466929909869), ('uniform_sampling', 1211, 0.04485971516382228), ('uniform_sampling', 1211, 0.04030477920676324), ('uniform_sampling', 1211, 0.050071022505949435), ('uniform_sampling', 1211, 0.0486783516501419), ('uniform_sampling', 1211, 0.04331931230751727), ('uniform_sampling', 1211, 0.04751156154825748), ('uniform_sampling', 1413, 0.03459576669398147), ('uniform_sampling', 1413, 0.0710798806550334), ('uniform_sampling', 1413, 0.07717682088197954), ('uniform_sampling', 1413, 0.06349439649118585), ('uniform_sampling', 1413, 0.052319636017587635), ('uniform_sampling', 1413, 0.05489940191345529), ('uniform_sampling', 1413, 0.04981355392103425), ('uniform_sampling', 1413, 0.04495299936536324), ('uniform_sampling', 1413, 0.04074788274846031), ('uniform_sampling', 1413, 0.043626075062573), ('uniform_sampling', 1615, 0.003463113236403399), ('uniform_sampling', 1615, 0.012712768921728096), ('uniform_sampling', 1615, 0.023706030763786065), ('uniform_sampling', 1615, 0.02125856441402514), ('uniform_sampling', 1615, 0.028233511215724916), ('uniform_sampling', 1615, 0.030049848626465193), ('uniform_sampling', 1615, 0.029455013653168823), ('uniform_sampling', 1615, 0.03410968260631407), ('uniform_sampling', 1615, 0.03771215642761546), ('uniform_sampling', 1615, 0.03656847185294228), ('uniform_sampling', 1817, 0.04221591034708136), ('uniform_sampling', 1817, 0.02217343811820091), ('uniform_sampling', 1817, 0.031723721602588316), ('uniform_sampling', 1817, 0.04353591068357582), ('uniform_sampling', 1817, 0.042465213751978335), ('uniform_sampling', 1817, 0.03811019928576068), ('uniform_sampling', 1817, 0.03930320412634341), ('uniform_sampling', 1817, 0.0464513085408523), ('uniform_sampling', 1817, 0.046340514763365946), ('uniform_sampling', 1817, 0.04326762662685253), ('uniform_sampling', 2019, 0.0006591058515195165), ('uniform_sampling', 2019, 0.03664511519241445), ('uniform_sampling', 2019, 0.039689848867437066), ('uniform_sampling', 2019, 0.04041866874813685), ('uniform_sampling', 2019, 0.035101497488325015), ('uniform_sampling', 2019, 0.029951812190592925), ('uniform_sampling', 2019, 0.030275573831354242), ('uniform_sampling', 2019, 0.034564795004771276), ('uniform_sampling', 2019, 0.03156527337347996), ('uniform_sampling', 2019, 0.03318050717897507)]\n",
                        "Times: [('uniform_sampling', 201, 0.16481661796569824), ('uniform_sampling', 403, 0.40008537769317626), ('uniform_sampling', 605, 0.46116943359375), ('uniform_sampling', 807, 0.630516767501831), ('uniform_sampling', 1009, 0.7430790901184082), ('uniform_sampling', 1211, 0.9620682001113892), ('uniform_sampling', 1413, 1.0631184577941895), ('uniform_sampling', 1615, 1.4233473300933839), ('uniform_sampling', 1817, 2.1512490272521974), ('uniform_sampling', 2019, 1.7894462108612061)]\n"
                    ]
                }
            ],
            "source": [
                "# Sampling Testing Function\n",
                "def testing_graph_methods_sampling(graph, accuracies, times,algo):\n",
                " \n",
                "    exact_netx_result = exact_netx(graph)\n",
                "    exact_triangles = exact_netx_result['triangles']\n",
                "    print(f\"Exact NetworkX Triangles: {exact_triangles}, Time: {exact_netx_result['time']}s\")\n",
                " \n",
                "    total_nodes = len(graph.nodes())\n",
                "    sample_sizes = [int(total_nodes * percentage / 100) for percentage in range(5,55,5) ]\n",
                "    algo_name=algo.__name__\n",
                " \n",
                "# create for loop for trials and another for loop for sample size according to sampling; between 5% and 50% in increments of 5% f the sample size given.\n",
                "    # evaluate each method with respective names according to the methods being used\n",
                "    for sample_size in sample_sizes:\n",
                "            method_accuracies = []\n",
                "            method_times = []\n",
                " \n",
                "            # Run 10 trials for the current method and sample size\n",
                "            for trial in range(1, 11):\n",
                "                print(f\"Trial {trial} for {algo_name} with Sample Size: {sample_size}\")\n",
                "                \n",
                "                result = algo(graph, sample_size)\n",
                "                rel_error = abs(exact_triangles - result['triangles']) / exact_triangles\n",
                "                method_accuracies.append(rel_error)\n",
                " \n",
                "                method_times.append(result['time'])\n",
                "                avg_acc = sum(method_accuracies) / len(method_accuracies)\n",
                "                accuracies.append((algo_name, sample_size, avg_acc))\n",
                "            avg_time = sum(method_times) / len(method_times)\n",
                "            times.append((algo_name, sample_size, avg_time))\n",
                "            print(f\"{algo_name} with sample size: {sample_size}: average accuracy: {avg_acc}, average time: {avg_time}s\")\n",
                " \n",
                " \n",
                "accuracies = []\n",
                "times = []\n",
                " \n",
                "fb_graph = nx.read_edgelist('facebook_combined.txt', create_using=nx.Graph(), nodetype=int)\n",
                " \n",
                "testing_graph_methods_sampling(fb_graph, accuracies, times,uniform_sampling)\n",
                " \n",
                "print(\"Accuracies:\", accuracies)\n",
                "print(\"Times:\", times)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Exact NetworkX Triangles: 1612010.0, Time: 0.4792501926422119s\n",
                        "Trial 1 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 1.4708523750305176s\n",
                        "Trial 2 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 1.0827844142913818s\n",
                        "Trial 3 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 1.0704406102498372s\n",
                        "Trial 4 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.9863248467445374s\n",
                        "Trial 5 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.9262290000915527s\n",
                        "Trial 6 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.8962364991505941s\n",
                        "Trial 7 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.9442036492483956s\n",
                        "Trial 8 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 1.0049360692501068s\n",
                        "Trial 9 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.9847928153143989s\n",
                        "Trial 10 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.9571964979171753s\n",
                        "Accuracies: [('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0)]\n",
                        "Times: [('exact_trace', 1.4708523750305176), ('exact_trace', 1.0827844142913818), ('exact_trace', 1.0704406102498372), ('exact_trace', 0.9863248467445374), ('exact_trace', 0.9262290000915527), ('exact_trace', 0.8962364991505941), ('exact_trace', 0.9442036492483956), ('exact_trace', 1.0049360692501068), ('exact_trace', 0.9847928153143989), ('exact_trace', 0.9571964979171753)]\n"
                    ]
                }
            ],
            "source": [
                "#Regular Testing Function\n",
                "def testing_graph_methods_regular(graph, accuracies, times,algo):\n",
                " \n",
                "    exact_netx_result = exact_netx(graph)\n",
                "    exact_triangles = exact_netx_result['triangles']\n",
                "    print(f\"Exact NetworkX Triangles: {exact_triangles}, Time: {exact_netx_result['time']}s\")\n",
                " \n",
                "    total_nodes = len(graph.nodes())\n",
                "    algo_name=algo.__name__\n",
                " \n",
                "# create for loop for trials\n",
                "    method_accuracies = []\n",
                "    method_times = []\n",
                "    # Run 10 trials for the current method\n",
                "    for trial in range(1, 11):\n",
                "        print(f\"Trial {trial} for {algo_name}\")\n",
                "        result = algo(graph)\n",
                "        rel_error = abs(exact_triangles - result['triangles']) / exact_triangles\n",
                "        method_accuracies.append(rel_error)\n",
                "        method_times.append(result['time'])\n",
                "        avg_acc = sum(method_accuracies) / len(method_accuracies)\n",
                "        accuracies.append((algo_name, avg_acc))\n",
                "        avg_time = sum(method_times) / len(method_times)\n",
                "        times.append((algo_name, avg_time))\n",
                "        print(f\"{algo_name} with average accuracy: {avg_acc}, average time: {avg_time}s\")\n",
                " \n",
                " \n",
                "accuracies = []\n",
                "times = []\n",
                " \n",
                "fb_graph = nx.read_edgelist('facebook_combined.txt', create_using=nx.Graph(), nodetype=int)\n",
                " \n",
                "testing_graph_methods_regular(fb_graph, accuracies, times,exact_trace)\n",
                " \n",
                "print(\"Accuracies:\", accuracies)\n",
                "print(\"Times:\", times)\n"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
