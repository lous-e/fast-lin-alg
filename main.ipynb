{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "id": "KmnOPlm1_Zdd"
            },
            "outputs": [],
            "source": [
                "import networkx as nx\n",
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import random\n",
                "import time\n",
                "import csv"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "id": "7_A_3AvUxW08"
            },
            "outputs": [],
            "source": [
                "def exact_netx(graph):\n",
                "  start = time.time()\n",
                "  t = sum(nx.triangles(graph).values())/3\n",
                "  end = time.time()\n",
                "  return {\"triangles\": t, \"time\": end - start}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "id": "huHhqhPQN86t"
            },
            "outputs": [],
            "source": [
                "def exact_trace(graph):\n",
                "  start = time.time()\n",
                "  adj_matrix = nx.adjacency_matrix(graph, dtype = np.float64)\n",
                "  adj_matrix_cubed = adj_matrix @ adj_matrix @ adj_matrix\n",
                "  t = adj_matrix_cubed.trace()/6\n",
                "  end = time.time()\n",
                "  return {\"triangles\": t, \"time\": end - start}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "id": "FtTYYA63qt6P"
            },
            "outputs": [],
            "source": [
                "def uniform_sampling(graph, sample_size):\n",
                "  start = time.time()\n",
                "  nodes = list(graph.nodes)\n",
                "  n = len(nodes)\n",
                "  node_sample = random.sample(nodes, sample_size)\n",
                "  sample_t = 0\n",
                "  for node in node_sample:\n",
                "    sample_t += nx.triangles(graph, node)\n",
                "  sample_t /= 3\n",
                "  t = sample_t*n/sample_size\n",
                "  end = time.time()\n",
                "  return {\"triangles\": t, \"time\": end - start}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "id": "NCJYKqJxChh5"
            },
            "outputs": [],
            "source": [
                "def random_sampling_with_degrees(graph, sample_size):\n",
                "  start = time.time()\n",
                "  nodes = []\n",
                "  degrees = []\n",
                "  sum_of_degrees=0\n",
                "  for node in graph:\n",
                "    nodes.append(node)\n",
                "    degree=graph.degree(node)\n",
                "    degrees.append(degree)\n",
                "    sum_of_degrees+=degree\n",
                "  node_sample = random.choices(nodes, weights = degrees, k = sample_size)\n",
                "  sample_t = 0\n",
                "  for node in node_sample:\n",
                "    sample_t += nx.triangles(graph, node)/graph.degree(node)\n",
                "  t = sample_t*sum_of_degrees/3\n",
                "  end = time.time()\n",
                "  return {\"triangles\": t, \"time\": end - start}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "def hutchplusplus(graph, queries):\n",
                "    start = time.time()\n",
                "    #to fix\n",
                "    #fast operations\n",
                "    #A.A.A.S\n",
                "    adj = nx.adjacency_matrix(graph, dtype = np.float64)\n",
                "    d = adj.shape[0]\n",
                "    S = np.random.choice([1, -1], size = (d, queries/3))\n",
                "    G = np.random.choice([1, -1], size = (d, queries/3))\n",
                "    Q, R = np.linalg.qr(A @ S)\n",
                "    trace = np.trace(np.transpose(Q) @ A @ Q) + 3/queries*(np.trace(np.transpose(G) @ (np.eye(d) - Q @ np.transpose(Q)) @ A @ (np.eye(d) - Q @ np.transpose(Q)) @ G))\n",
                "    t = trace/6\n",
                "    end = time.time()\n",
                "    return {\"triangles\": t, \"time\": end - start}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# def lanczos(A, m):\n",
                "#     n = A.shape[0]\n",
                "#     v = [np.random.rand(n)]\n",
                "#     w_prime = [A @ v[0]]\n",
                "#     alpha = [w_prime[0] * v[0]]\n",
                "#     beta = []\n",
                "#     w = [w_prime[0] - alpha[0] @ v[0]]\n",
                "#     for j in range(2, m + 1):\n",
                "#         beta_j = np.linalg.norm(w[-1])\n",
                "#         beta.push(beta_j)\n",
                "#         if beta_j != 0:\n",
                "#             v_j = w[-1]/beta_j\n",
                "#         else:\n",
                "#             v_j = #TODO\n",
                "#         v.push(v_j)\n",
                "#         w_prime.push(A @ v[-1])\n",
                "#         alpha.push(w_prime[-1]*v[-1])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "# def eigenTriangle(graph, sample_size, tol):\n",
                "#   adj_matrix = nx.adjacency_matrix(graph, dtype = np.float64)\n",
                "#   nodes = list(graph.nodes)\n",
                "#   n = len(nodes)\n",
                "#   node_sample = random.sample(nodes, sample_size)\n",
                "#   for node in node_sample:\n",
                "#     lambda_1 = lanczos(A, 1)\n",
                "#     eigen = lambda_1\n",
                "#     i = 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Exact NetworkX Triangles: 1612010.0, Time: 0.5708951950073242s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 201\n",
                        "Trial 2 for uniform_sampling with Sample Size: 201\n",
                        "Trial 3 for uniform_sampling with Sample Size: 201\n",
                        "Trial 4 for uniform_sampling with Sample Size: 201\n",
                        "Trial 5 for uniform_sampling with Sample Size: 201\n",
                        "Trial 6 for uniform_sampling with Sample Size: 201\n",
                        "Trial 7 for uniform_sampling with Sample Size: 201\n",
                        "Trial 8 for uniform_sampling with Sample Size: 201\n",
                        "Trial 9 for uniform_sampling with Sample Size: 201\n",
                        "Trial 10 for uniform_sampling with Sample Size: 201\n",
                        "uniform_sampling with sample size: 201: average accuracy: 0.18683218317216177, average time: 0.15373585224151612s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 403\n",
                        "Trial 2 for uniform_sampling with Sample Size: 403\n",
                        "Trial 3 for uniform_sampling with Sample Size: 403\n",
                        "Trial 4 for uniform_sampling with Sample Size: 403\n",
                        "Trial 5 for uniform_sampling with Sample Size: 403\n",
                        "Trial 6 for uniform_sampling with Sample Size: 403\n",
                        "Trial 7 for uniform_sampling with Sample Size: 403\n",
                        "Trial 8 for uniform_sampling with Sample Size: 403\n",
                        "Trial 9 for uniform_sampling with Sample Size: 403\n",
                        "Trial 10 for uniform_sampling with Sample Size: 403\n",
                        "uniform_sampling with sample size: 403: average accuracy: 0.06413353566487173, average time: 0.42486565113067626s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 605\n",
                        "Trial 2 for uniform_sampling with Sample Size: 605\n",
                        "Trial 3 for uniform_sampling with Sample Size: 605\n",
                        "Trial 4 for uniform_sampling with Sample Size: 605\n",
                        "Trial 5 for uniform_sampling with Sample Size: 605\n",
                        "Trial 6 for uniform_sampling with Sample Size: 605\n",
                        "Trial 7 for uniform_sampling with Sample Size: 605\n",
                        "Trial 8 for uniform_sampling with Sample Size: 605\n",
                        "Trial 9 for uniform_sampling with Sample Size: 605\n",
                        "Trial 10 for uniform_sampling with Sample Size: 605\n",
                        "uniform_sampling with sample size: 605: average accuracy: 0.07208848795669649, average time: 0.47163727283477785s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 807\n",
                        "Trial 2 for uniform_sampling with Sample Size: 807\n",
                        "Trial 3 for uniform_sampling with Sample Size: 807\n",
                        "Trial 4 for uniform_sampling with Sample Size: 807\n",
                        "Trial 5 for uniform_sampling with Sample Size: 807\n",
                        "Trial 6 for uniform_sampling with Sample Size: 807\n",
                        "Trial 7 for uniform_sampling with Sample Size: 807\n",
                        "Trial 8 for uniform_sampling with Sample Size: 807\n",
                        "Trial 9 for uniform_sampling with Sample Size: 807\n",
                        "Trial 10 for uniform_sampling with Sample Size: 807\n",
                        "uniform_sampling with sample size: 807: average accuracy: 0.06182045578923392, average time: 0.8008754253387451s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 2 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 3 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 4 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 5 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 6 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 7 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 8 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 9 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 10 for uniform_sampling with Sample Size: 1009\n",
                        "uniform_sampling with sample size: 1009: average accuracy: 0.04405966512592963, average time: 0.8948039054870606s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 2 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 3 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 4 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 5 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 6 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 7 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 8 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 9 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 10 for uniform_sampling with Sample Size: 1211\n",
                        "uniform_sampling with sample size: 1211: average accuracy: 0.03619338470184286, average time: 1.1017679452896119s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 2 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 3 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 4 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 5 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 6 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 7 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 8 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 9 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 10 for uniform_sampling with Sample Size: 1413\n",
                        "uniform_sampling with sample size: 1413: average accuracy: 0.036579395276086654, average time: 1.1014882802963257s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 2 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 3 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 4 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 5 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 6 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 7 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 8 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 9 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 10 for uniform_sampling with Sample Size: 1615\n",
                        "uniform_sampling with sample size: 1615: average accuracy: 0.03548786635231575, average time: 1.1680206537246705s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 2 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 3 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 4 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 5 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 6 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 7 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 8 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 9 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 10 for uniform_sampling with Sample Size: 1817\n",
                        "uniform_sampling with sample size: 1817: average accuracy: 0.026921317817588684, average time: 1.3836114645004272s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 2 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 3 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 4 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 5 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 6 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 7 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 8 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 9 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 10 for uniform_sampling with Sample Size: 2019\n",
                        "uniform_sampling with sample size: 2019: average accuracy: 0.019699227081949714, average time: 1.439681625366211s\n",
                        "Accuracies: [('uniform_sampling', 201, 0.28802378946515306), ('uniform_sampling', 201, 0.24782044095356662), ('uniform_sampling', 201, 0.22409104882018324), ('uniform_sampling', 201, 0.20609013634935108), ('uniform_sampling', 201, 0.18807959281349182), ('uniform_sampling', 201, 0.19897650807685066), ('uniform_sampling', 201, 0.2038045452182174), ('uniform_sampling', 201, 0.18582696431861076), ('uniform_sampling', 201, 0.18916453552025017), ('uniform_sampling', 201, 0.18683218317216177), ('uniform_sampling', 403, 0.034668433737578254), ('uniform_sampling', 403, 0.043592316296559894), ('uniform_sampling', 403, 0.06454803524892942), ('uniform_sampling', 403, 0.05803456120666292), ('uniform_sampling', 403, 0.04818531815740072), ('uniform_sampling', 403, 0.050442871245001485), ('uniform_sampling', 403, 0.04514083599130901), ('uniform_sampling', 403, 0.05859245952972861), ('uniform_sampling', 403, 0.064724790685948), ('uniform_sampling', 403, 0.06413353566487173), ('uniform_sampling', 605, 0.06863980517589693), ('uniform_sampling', 605, 0.1361610552320569), ('uniform_sampling', 605, 0.09117150705241457), ('uniform_sampling', 605, 0.09451323026162957), ('uniform_sampling', 605, 0.08137027901258323), ('uniform_sampling', 605, 0.08229512569074525), ('uniform_sampling', 605, 0.07841327409606647), ('uniform_sampling', 605, 0.0742707521535619), ('uniform_sampling', 605, 0.0783884854348775), ('uniform_sampling', 605, 0.07208848795669649), ('uniform_sampling', 807, 0.005332101583697603), ('uniform_sampling', 807, 0.05675095052274398), ('uniform_sampling', 807, 0.046576418817657124), ('uniform_sampling', 807, 0.04853159865394014), ('uniform_sampling', 807, 0.05131665970311183), ('uniform_sampling', 807, 0.045425058249110244), ('uniform_sampling', 807, 0.04718832248997378), ('uniform_sampling', 807, 0.04985731060686687), ('uniform_sampling', 807, 0.05284542429980944), ('uniform_sampling', 807, 0.06182045578923392), ('uniform_sampling', 1009, 0.03616352646898626), ('uniform_sampling', 1009, 0.045992519620034866), ('uniform_sampling', 1009, 0.040958621684380477), ('uniform_sampling', 1009, 0.04791763495439105), ('uniform_sampling', 1009, 0.04901964600959345), ('uniform_sampling', 1009, 0.04666188509604726), ('uniform_sampling', 1009, 0.04190165356464589), ('uniform_sampling', 1009, 0.036726596392584035), ('uniform_sampling', 1009, 0.04089414999420065), ('uniform_sampling', 1009, 0.04405966512592963), ('uniform_sampling', 1211, 0.023786592783869884), ('uniform_sampling', 1211, 0.02214173214906768), ('uniform_sampling', 1211, 0.02187092211024207), ('uniform_sampling', 1211, 0.04010834604828431), ('uniform_sampling', 1211, 0.0379795032994089), ('uniform_sampling', 1211, 0.037129826473495116), ('uniform_sampling', 1211, 0.03393143381544033), ('uniform_sampling', 1211, 0.03555608223001527), ('uniform_sampling', 1211, 0.03613462642783484), ('uniform_sampling', 1211, 0.03619338470184286), ('uniform_sampling', 1413, 0.03105049791247659), ('uniform_sampling', 1413, 0.05186388950202509), ('uniform_sampling', 1413, 0.03917493104441479), ('uniform_sampling', 1413, 0.03067908601909708), ('uniform_sampling', 1413, 0.029099957831712032), ('uniform_sampling', 1413, 0.027300973323219166), ('uniform_sampling', 1413, 0.026440922372827903), ('uniform_sampling', 1413, 0.027623414655835614), ('uniform_sampling', 1413, 0.040037607436838346), ('uniform_sampling', 1413, 0.036579395276086654), ('uniform_sampling', 1615, 0.02286835934157256), ('uniform_sampling', 1615, 0.05179310724570292), ('uniform_sampling', 1615, 0.054081370512043626), ('uniform_sampling', 1615, 0.045113765724820655), ('uniform_sampling', 1615, 0.04468869321584682), ('uniform_sampling', 1615, 0.05073999317733067), ('uniform_sampling', 1615, 0.044953288236140934), ('uniform_sampling', 1615, 0.04175149570174586), ('uniform_sampling', 1615, 0.03794001055406319), ('uniform_sampling', 1615, 0.03548786635231575), ('uniform_sampling', 1817, 0.03287527443558634), ('uniform_sampling', 1817, 0.022902876434470056), ('uniform_sampling', 1817, 0.026601329966110216), ('uniform_sampling', 1817, 0.025197815789606413), ('uniform_sampling', 1817, 0.02692618399220468), ('uniform_sampling', 1817, 0.02276552708904744), ('uniform_sampling', 1817, 0.025082990149608603), ('uniform_sampling', 1817, 0.02466066168139199), ('uniform_sampling', 1817, 0.02463882349489324), ('uniform_sampling', 1817, 0.026921317817588684), ('uniform_sampling', 2019, 0.056784729780578844), ('uniform_sampling', 2019, 0.04727995408929282), ('uniform_sampling', 2019, 0.032240941156155424), ('uniform_sampling', 2019, 0.030104040830293218), ('uniform_sampling', 2019, 0.02428372218831634), ('uniform_sampling', 2019, 0.02452301348258609), ('uniform_sampling', 2019, 0.02404919001764818), ('uniform_sampling', 2019, 0.02233710535085512), ('uniform_sampling', 2019, 0.020907537315571247), ('uniform_sampling', 2019, 0.019699227081949714)]\n",
                        "Times: [('uniform_sampling', 201, 0.15373585224151612), ('uniform_sampling', 403, 0.42486565113067626), ('uniform_sampling', 605, 0.47163727283477785), ('uniform_sampling', 807, 0.8008754253387451), ('uniform_sampling', 1009, 0.8948039054870606), ('uniform_sampling', 1211, 1.1017679452896119), ('uniform_sampling', 1413, 1.1014882802963257), ('uniform_sampling', 1615, 1.1680206537246705), ('uniform_sampling', 1817, 1.3836114645004272), ('uniform_sampling', 2019, 1.439681625366211)]\n"
                    ]
                }
            ],
            "source": [
                "# Sampling Testing Function\n",
                "def testing_graph_methods_sampling(graph, accuracies, times,algo):\n",
                " \n",
                "    exact_netx_result = exact_netx(graph)\n",
                "    exact_triangles = exact_netx_result['triangles']\n",
                "    print(f\"Exact NetworkX Triangles: {exact_triangles}, Time: {exact_netx_result['time']}s\")\n",
                " \n",
                "    total_nodes = len(graph.nodes())\n",
                "    sample_sizes = [int(total_nodes * percentage / 100) for percentage in range(5,55,5) ]\n",
                "    algo_name=algo.__name__\n",
                " \n",
                "# create for loop for trials and another for loop for sample size according to sampling; between 5% and 50% in increments of 5% f the sample size given.\n",
                "    # evaluate each method with respective names according to the methods being used\n",
                "    for sample_size in sample_sizes:\n",
                "            method_accuracies = []\n",
                "            method_times = []\n",
                " \n",
                "            # Run 10 trials for the current method and sample size\n",
                "            for trial in range(1, 11):\n",
                "                print(f\"Trial {trial} for {algo_name} with Sample Size: {sample_size}\")\n",
                "                \n",
                "                result = algo(graph, sample_size)\n",
                "                rel_error = abs(exact_triangles - result['triangles']) / exact_triangles\n",
                "                method_accuracies.append(rel_error)\n",
                " \n",
                "                method_times.append(result['time'])\n",
                "                avg_acc = sum(method_accuracies) / len(method_accuracies)\n",
                "                accuracies.append((algo_name, sample_size, avg_acc))\n",
                "            avg_time = sum(method_times) / len(method_times)\n",
                "            times.append((algo_name, sample_size, avg_time))\n",
                "            print(f\"{algo_name} with sample size: {sample_size}: average accuracy: {avg_acc}, average time: {avg_time}s\")\n",
                " \n",
                "accuracies = []\n",
                "times = []\n",
                " \n",
                "fb_graph = nx.read_edgelist('facebook_combined.txt', create_using=nx.Graph(), nodetype=int)\n",
                " \n",
                "testing_graph_methods_sampling(fb_graph, accuracies, times,uniform_sampling)\n",
                " \n",
                "print(\"Accuracies:\", accuracies)\n",
                "print(\"Times:\", times)\n",
                "with open('output.csv', 'w', newline='') as csvfile:\n",
                "    writer = csv.writer(csvfile)\n",
                "    writer.writerows(accuracies)\n",
                "    writer.writerows(times)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Exact NetworkX Triangles: 1612010.0, Time: 0.48077869415283203s\n",
                        "Trial 1 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 1.404020071029663s\n",
                        "Trial 2 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 1.1388757228851318s\n",
                        "Trial 3 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.9810603459676107s\n",
                        "Trial 4 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.9242104291915894s\n",
                        "Trial 5 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.875962209701538s\n",
                        "Trial 6 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.8502724170684814s\n",
                        "Trial 7 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.8630331584385463s\n",
                        "Trial 8 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.8562715947628021s\n",
                        "Trial 9 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.8520763715108236s\n",
                        "Trial 10 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.8323745250701904s\n",
                        "Accuracies: [('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0)]\n",
                        "Times: [('exact_trace', 1.404020071029663), ('exact_trace', 1.1388757228851318), ('exact_trace', 0.9810603459676107), ('exact_trace', 0.9242104291915894), ('exact_trace', 0.875962209701538), ('exact_trace', 0.8502724170684814), ('exact_trace', 0.8630331584385463), ('exact_trace', 0.8562715947628021), ('exact_trace', 0.8520763715108236), ('exact_trace', 0.8323745250701904)]\n"
                    ]
                }
            ],
            "source": [
                "#Regular Testing Function\n",
                "def testing_graph_methods_regular(graph, accuracies, times,algo):\n",
                " \n",
                "    exact_netx_result = exact_netx(graph)\n",
                "    exact_triangles = exact_netx_result['triangles']\n",
                "    print(f\"Exact NetworkX Triangles: {exact_triangles}, Time: {exact_netx_result['time']}s\")\n",
                " \n",
                "    total_nodes = len(graph.nodes())\n",
                "    algo_name=algo.__name__\n",
                " \n",
                "# create for loop for trials\n",
                "    method_accuracies = []\n",
                "    method_times = []\n",
                "    # Run 10 trials for the current method\n",
                "    for trial in range(1, 11):\n",
                "        print(f\"Trial {trial} for {algo_name}\")\n",
                "        result = algo(graph)\n",
                "        rel_error = abs(exact_triangles - result['triangles']) / exact_triangles\n",
                "        method_accuracies.append(rel_error)\n",
                "        method_times.append(result['time'])\n",
                "        avg_acc = sum(method_accuracies) / len(method_accuracies)\n",
                "        accuracies.append((algo_name, avg_acc))\n",
                "        avg_time = sum(method_times) / len(method_times)\n",
                "        times.append((algo_name, avg_time))\n",
                "        print(f\"{algo_name} with average accuracy: {avg_acc}, average time: {avg_time}s\")\n",
                " \n",
                " \n",
                "accuracies = []\n",
                "times = []\n",
                " \n",
                "fb_graph = nx.read_edgelist('facebook_combined.txt', create_using=nx.Graph(), nodetype=int)\n",
                " \n",
                "testing_graph_methods_regular(fb_graph, accuracies, times,exact_trace)\n",
                " \n",
                "print(\"Accuracies:\", accuracies)\n",
                "print(\"Times:\", times)\n"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
