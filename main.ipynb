{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "id": "KmnOPlm1_Zdd"
            },
            "outputs": [],
            "source": [
                "import networkx as nx\n",
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import random\n",
                "import time\n",
                "import csv"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "id": "7_A_3AvUxW08"
            },
            "outputs": [],
            "source": [
                "def exact_netx(graph):\n",
                "  start = time.time()\n",
                "  t = sum(nx.triangles(graph).values())/3\n",
                "  end = time.time()\n",
                "  return {\"triangles\": t, \"time\": end - start}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "id": "huHhqhPQN86t"
            },
            "outputs": [],
            "source": [
                "def exact_trace(graph):\n",
                "  start = time.time()\n",
                "  adj_matrix = nx.adjacency_matrix(graph, dtype = np.float64)\n",
                "  adj_matrix_cubed = adj_matrix @ adj_matrix @ adj_matrix\n",
                "  t = adj_matrix_cubed.trace()/6\n",
                "  end = time.time()\n",
                "  return {\"triangles\": t, \"time\": end - start}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "id": "FtTYYA63qt6P"
            },
            "outputs": [],
            "source": [
                "def uniform_sampling(graph, sample_size):\n",
                "  start = time.time()\n",
                "  nodes = list(graph.nodes)\n",
                "  n = len(nodes)\n",
                "  node_sample = random.sample(nodes, sample_size)\n",
                "  sample_t = 0\n",
                "  for node in node_sample:\n",
                "    sample_t += nx.triangles(graph, node)\n",
                "  sample_t /= 3\n",
                "  t = sample_t*n/sample_size\n",
                "  end = time.time()\n",
                "  return {\"triangles\": t, \"time\": end - start}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "id": "NCJYKqJxChh5"
            },
            "outputs": [],
            "source": [
                "def random_sampling_with_degrees(graph, sample_size):\n",
                "  start = time.time()\n",
                "  nodes = []\n",
                "  degrees = []\n",
                "  sum_of_degrees=0\n",
                "  for node in graph:\n",
                "    nodes.append(node)\n",
                "    degree=graph.degree(node)\n",
                "    degrees.append(degree)\n",
                "    sum_of_degrees+=degree\n",
                "  node_sample = random.choices(nodes, weights = degrees, k = sample_size)\n",
                "  sample_t = 0\n",
                "  for node in node_sample:\n",
                "    sample_t += nx.triangles(graph, node)/graph.degree(node)\n",
                "  t = sample_t*sum_of_degrees/3\n",
                "  end = time.time()\n",
                "  return {\"triangles\": t, \"time\": end - start}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "def hutchplusplus(graph, queries):\n",
                "    start = time.time()\n",
                "    A = nx.adjacency_matrix(graph, dtype = np.float64)\n",
                "    d = A.shape[0]\n",
                "    S = np.random.choice([1, -1], size = (d, queries//3))\n",
                "    G = np.random.choice([1, -1], size = (d, queries//3))\n",
                "    Q, R = np.linalg.qr(A @ (A @ (A @ S)))\n",
                "    term_1 = np.trace(Q.T @ (A @ (A @ (A @ Q))))\n",
                "    term_prod = G - Q @ (Q.T @ G)\n",
                "    term_2 = 3/queries*np.trace(term_prod.T @ (A @ (A @ (A @ term_prod))))\n",
                "    t = term_1/6 + (term_2 - term_1)/6\n",
                "    end = time.time()\n",
                "    return {\"triangles\": t, \"time\": end - start}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# def lanczos(A, m):\n",
                "#     n = A.shape[0]\n",
                "#     v = [np.random.rand(n)]\n",
                "#     w_prime = [A @ v[0]]\n",
                "#     alpha = [w_prime[0] * v[0]]\n",
                "#     beta = []\n",
                "#     w = [w_prime[0] - alpha[0] @ v[0]]\n",
                "#     for j in range(2, m + 1):\n",
                "#         beta_j = np.linalg.norm(w[-1])\n",
                "#         beta.push(beta_j)\n",
                "#         if beta_j != 0:\n",
                "#             v_j = w[-1]/beta_j\n",
                "#         else:\n",
                "#             v_j = #TODO\n",
                "#         v.push(v_j)\n",
                "#         w_prime.push(A @ v[-1])\n",
                "#         alpha.push(w_prime[-1]*v[-1])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "# def eigenTriangle(graph, sample_size, tol):\n",
                "#   adj_matrix = nx.adjacency_matrix(graph, dtype = np.float64)\n",
                "#   nodes = list(graph.nodes)\n",
                "#   n = len(nodes)\n",
                "#   node_sample = random.sample(nodes, sample_size)\n",
                "#   for node in node_sample:\n",
                "#     lambda_1 = lanczos(A, 1)\n",
                "#     eigen = lambda_1\n",
                "#     i = 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Exact NetworkX Triangles: 1612010.0, Time: 0.5682752132415771s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 201\n",
                        "Trial 2 for uniform_sampling with Sample Size: 201\n",
                        "Trial 3 for uniform_sampling with Sample Size: 201\n",
                        "Trial 4 for uniform_sampling with Sample Size: 201\n",
                        "Trial 5 for uniform_sampling with Sample Size: 201\n",
                        "Trial 6 for uniform_sampling with Sample Size: 201\n",
                        "Trial 7 for uniform_sampling with Sample Size: 201\n",
                        "Trial 8 for uniform_sampling with Sample Size: 201\n",
                        "Trial 9 for uniform_sampling with Sample Size: 201\n",
                        "Trial 10 for uniform_sampling with Sample Size: 201\n",
                        "uniform_sampling with sample size: 201: average accuracy: 0.13478540840461398, average time: 0.13154542446136475s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 403\n",
                        "Trial 2 for uniform_sampling with Sample Size: 403\n",
                        "Trial 3 for uniform_sampling with Sample Size: 403\n",
                        "Trial 4 for uniform_sampling with Sample Size: 403\n",
                        "Trial 5 for uniform_sampling with Sample Size: 403\n",
                        "Trial 6 for uniform_sampling with Sample Size: 403\n",
                        "Trial 7 for uniform_sampling with Sample Size: 403\n",
                        "Trial 8 for uniform_sampling with Sample Size: 403\n",
                        "Trial 9 for uniform_sampling with Sample Size: 403\n",
                        "Trial 10 for uniform_sampling with Sample Size: 403\n",
                        "uniform_sampling with sample size: 403: average accuracy: 0.09476259716733693, average time: 0.29833168983459474s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 605\n",
                        "Trial 2 for uniform_sampling with Sample Size: 605\n",
                        "Trial 3 for uniform_sampling with Sample Size: 605\n",
                        "Trial 4 for uniform_sampling with Sample Size: 605\n",
                        "Trial 5 for uniform_sampling with Sample Size: 605\n",
                        "Trial 6 for uniform_sampling with Sample Size: 605\n",
                        "Trial 7 for uniform_sampling with Sample Size: 605\n",
                        "Trial 8 for uniform_sampling with Sample Size: 605\n",
                        "Trial 9 for uniform_sampling with Sample Size: 605\n",
                        "Trial 10 for uniform_sampling with Sample Size: 605\n",
                        "uniform_sampling with sample size: 605: average accuracy: 0.06585680772270638, average time: 0.5294603824615478s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 807\n",
                        "Trial 2 for uniform_sampling with Sample Size: 807\n",
                        "Trial 3 for uniform_sampling with Sample Size: 807\n",
                        "Trial 4 for uniform_sampling with Sample Size: 807\n",
                        "Trial 5 for uniform_sampling with Sample Size: 807\n",
                        "Trial 6 for uniform_sampling with Sample Size: 807\n",
                        "Trial 7 for uniform_sampling with Sample Size: 807\n",
                        "Trial 8 for uniform_sampling with Sample Size: 807\n",
                        "Trial 9 for uniform_sampling with Sample Size: 807\n",
                        "Trial 10 for uniform_sampling with Sample Size: 807\n",
                        "uniform_sampling with sample size: 807: average accuracy: 0.07613321815903351, average time: 0.5600056409835815s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 2 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 3 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 4 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 5 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 6 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 7 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 8 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 9 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 10 for uniform_sampling with Sample Size: 1009\n",
                        "uniform_sampling with sample size: 1009: average accuracy: 0.060663375304564435, average time: 0.8368324756622314s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 2 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 3 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 4 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 5 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 6 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 7 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 8 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 9 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 10 for uniform_sampling with Sample Size: 1211\n",
                        "uniform_sampling with sample size: 1211: average accuracy: 0.04343630725431773, average time: 2.1336967945098877s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 2 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 3 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 4 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 5 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 6 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 7 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 8 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 9 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 10 for uniform_sampling with Sample Size: 1413\n",
                        "uniform_sampling with sample size: 1413: average accuracy: 0.031711682512932084, average time: 2.720089626312256s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 2 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 3 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 4 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 5 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 6 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 7 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 8 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 9 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 10 for uniform_sampling with Sample Size: 1615\n",
                        "uniform_sampling with sample size: 1615: average accuracy: 0.046757459405476924, average time: 1.1894464254379273s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 2 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 3 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 4 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 5 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 6 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 7 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 8 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 9 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 10 for uniform_sampling with Sample Size: 1817\n",
                        "uniform_sampling with sample size: 1817: average accuracy: 0.030061200162692266, average time: 1.2363759994506835s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 2 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 3 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 4 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 5 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 6 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 7 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 8 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 9 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 10 for uniform_sampling with Sample Size: 2019\n",
                        "uniform_sampling with sample size: 2019: average accuracy: 0.03341277995395258, average time: 1.4135319948196412s\n",
                        "Accuracies: [('uniform_sampling', 201, 0.014775922806547846), ('uniform_sampling', 201, 0.05197910063621436), ('uniform_sampling', 201, 0.06435384383533298), ('uniform_sampling', 201, 0.07117799525602822), ('uniform_sampling', 201, 0.0853704356796177), ('uniform_sampling', 201, 0.07538374292313267), ('uniform_sampling', 201, 0.1013819761035877), ('uniform_sampling', 201, 0.12198332925994984), ('uniform_sampling', 201, 0.1280743316555287), ('uniform_sampling', 201, 0.13478540840461398), ('uniform_sampling', 403, 0.062099529180798765), ('uniform_sampling', 403, 0.054167304263357446), ('uniform_sampling', 403, 0.12073754770178051), ('uniform_sampling', 403, 0.1102674598372066), ('uniform_sampling', 403, 0.11301622705320877), ('uniform_sampling', 403, 0.10675590030647865), ('uniform_sampling', 403, 0.09153188061189317), ('uniform_sampling', 403, 0.09172439453379541), ('uniform_sampling', 403, 0.10257841145702845), ('uniform_sampling', 403, 0.09476259716733693), ('uniform_sampling', 605, 0.0790395906156411), ('uniform_sampling', 605, 0.06714608234337696), ('uniform_sampling', 605, 0.046259220012608654), ('uniform_sampling', 605, 0.07020091902101998), ('uniform_sampling', 605, 0.06834808279580054), ('uniform_sampling', 605, 0.07042278474792713), ('uniform_sampling', 605, 0.07437349590035312), ('uniform_sampling', 605, 0.06995390544115289), ('uniform_sampling', 605, 0.06788396811766846), ('uniform_sampling', 605, 0.06585680772270638), ('uniform_sampling', 807, 0.1805324400714248), ('uniform_sampling', 807, 0.15028244631137366), ('uniform_sampling', 807, 0.1269623495104146), ('uniform_sampling', 807, 0.11583056438084577), ('uniform_sampling', 807, 0.10953674970642777), ('uniform_sampling', 807, 0.10559322389528529), ('uniform_sampling', 807, 0.09402844497973721), ('uniform_sampling', 807, 0.08475563583200771), ('uniform_sampling', 807, 0.07571400754253196), ('uniform_sampling', 807, 0.07613321815903351), ('uniform_sampling', 1009, 0.019765178674813776), ('uniform_sampling', 1009, 0.03404989365965182), ('uniform_sampling', 1009, 0.04575123361284663), ('uniform_sampling', 1009, 0.04545221268745103), ('uniform_sampling', 1009, 0.05095721868054968), ('uniform_sampling', 1009, 0.05081879302471615), ('uniform_sampling', 1009, 0.045326130255043014), ('uniform_sampling', 1009, 0.05360917202177156), ('uniform_sampling', 1009, 0.05331107081266711), ('uniform_sampling', 1009, 0.060663375304564435), ('uniform_sampling', 1211, 0.03898018556973585), ('uniform_sampling', 1211, 0.023837467528631064), ('uniform_sampling', 1211, 0.02193242536792019), ('uniform_sampling', 1211, 0.02054959683107958), ('uniform_sampling', 1211, 0.017261091685831884), ('uniform_sampling', 1211, 0.030338142175146885), ('uniform_sampling', 1211, 0.04093822817209945), ('uniform_sampling', 1211, 0.03655149307428264), ('uniform_sampling', 1211, 0.03733415503420586), ('uniform_sampling', 1211, 0.04343630725431773), ('uniform_sampling', 1413, 0.030655384000491687), ('uniform_sampling', 1413, 0.032560714763609576), ('uniform_sampling', 1413, 0.027903732127506412), ('uniform_sampling', 1413, 0.03761669280033977), ('uniform_sampling', 1413, 0.034240010455605846), ('uniform_sampling', 1413, 0.032266694215442114), ('uniform_sampling', 1413, 0.0290831971956463), ('uniform_sampling', 1413, 0.030808127592605983), ('uniform_sampling', 1413, 0.03335980231651352), ('uniform_sampling', 1413, 0.031711682512932084), ('uniform_sampling', 1615, 0.03699158962035028), ('uniform_sampling', 1615, 0.02581324161262709), ('uniform_sampling', 1615, 0.028522305758192024), ('uniform_sampling', 1615, 0.03878853925093189), ('uniform_sampling', 1615, 0.03710548561731567), ('uniform_sampling', 1615, 0.04219134477691977), ('uniform_sampling', 1615, 0.054043160873684534), ('uniform_sampling', 1615, 0.05012751244817913), ('uniform_sampling', 1615, 0.04828839250920306), ('uniform_sampling', 1615, 0.046757459405476924), ('uniform_sampling', 1817, 0.06445848012592317), ('uniform_sampling', 1817, 0.03927915768103135), ('uniform_sampling', 1817, 0.03270567278316866), ('uniform_sampling', 1817, 0.029775391104897832), ('uniform_sampling', 1817, 0.026339666979486625), ('uniform_sampling', 1817, 0.035812241564562815), ('uniform_sampling', 1817, 0.03149810205707497), ('uniform_sampling', 1817, 0.03620857337746494), ('uniform_sampling', 1817, 0.03288146786897495), ('uniform_sampling', 1817, 0.030061200162692266), ('uniform_sampling', 2019, 0.011624945552102816), ('uniform_sampling', 2019, 0.03087938648549697), ('uniform_sampling', 2019, 0.02628619063671443), ('uniform_sampling', 2019, 0.02567220870140596), ('uniform_sampling', 2019, 0.026127646728334473), ('uniform_sampling', 2019, 0.027510960152859604), ('uniform_sampling', 2019, 0.029695359719326464), ('uniform_sampling', 2019, 0.0330087432199546), ('uniform_sampling', 2019, 0.03269250990386927), ('uniform_sampling', 2019, 0.03341277995395258)]\n",
                        "Times: [('uniform_sampling', 201, 0.13154542446136475), ('uniform_sampling', 403, 0.29833168983459474), ('uniform_sampling', 605, 0.5294603824615478), ('uniform_sampling', 807, 0.5600056409835815), ('uniform_sampling', 1009, 0.8368324756622314), ('uniform_sampling', 1211, 2.1336967945098877), ('uniform_sampling', 1413, 2.720089626312256), ('uniform_sampling', 1615, 1.1894464254379273), ('uniform_sampling', 1817, 1.2363759994506835), ('uniform_sampling', 2019, 1.4135319948196412)]\n"
                    ]
                }
            ],
            "source": [
                "# Sampling Testing Function\n",
                "def testing_graph_methods_sampling(graph, accuracies, times,algo):\n",
                " \n",
                "    exact_netx_result = exact_netx(graph)\n",
                "    exact_triangles = exact_netx_result['triangles']\n",
                "    print(f\"Exact NetworkX Triangles: {exact_triangles}, Time: {exact_netx_result['time']}s\")\n",
                " \n",
                "    total_nodes = len(graph.nodes())\n",
                "    sample_sizes = [int(total_nodes * percentage / 100) for percentage in range(5,55,5) ]\n",
                "    algo_name=algo.__name__\n",
                " \n",
                "# create for loop for trials and another for loop for sample size according to sampling; between 5% and 50% in increments of 5% f the sample size given.\n",
                "    # evaluate each method with respective names according to the methods being used\n",
                "    for sample_size in sample_sizes:\n",
                "            method_accuracies = []\n",
                "            method_times = []\n",
                " \n",
                "            # Run 10 trials for the current method and sample size\n",
                "            for trial in range(1, 11):\n",
                "                print(f\"Trial {trial} for {algo_name} with Sample Size: {sample_size}\")\n",
                "                \n",
                "                result = algo(graph, sample_size)\n",
                "                rel_error = abs(exact_triangles - result['triangles']) / exact_triangles\n",
                "                method_accuracies.append(rel_error)\n",
                " \n",
                "                method_times.append(result['time'])\n",
                "                avg_acc = sum(method_accuracies) / len(method_accuracies)\n",
                "                accuracies.append((algo_name, sample_size, avg_acc))\n",
                "            avg_time = sum(method_times) / len(method_times)\n",
                "            times.append((algo_name, sample_size, avg_time))\n",
                "            print(f\"{algo_name} with sample size: {sample_size}: average accuracy: {avg_acc}, average time: {avg_time}s\")\n",
                " \n",
                "accuracies = []\n",
                "times = []\n",
                " \n",
                "fb_graph = nx.read_edgelist('facebook_combined.txt', create_using=nx.Graph(), nodetype=int)\n",
                " \n",
                "testing_graph_methods_sampling(fb_graph, accuracies, times,uniform_sampling)\n",
                " \n",
                "print(\"Accuracies:\", accuracies)\n",
                "print(\"Times:\", times)\n",
                "with open('output.csv', 'a', newline='') as csvfile:\n",
                "    writer = csv.writer(csvfile)\n",
                "    writer.writerows(accuracies)\n",
                "    writer.writerow(\"\\n\")\n",
                "    writer.writerows(times)\n",
                "    writer.writerow(\"\\n\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Exact NetworkX Triangles: 1612010.0, Time: 0.48077869415283203s\n",
                        "Trial 1 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 1.404020071029663s\n",
                        "Trial 2 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 1.1388757228851318s\n",
                        "Trial 3 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.9810603459676107s\n",
                        "Trial 4 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.9242104291915894s\n",
                        "Trial 5 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.875962209701538s\n",
                        "Trial 6 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.8502724170684814s\n",
                        "Trial 7 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.8630331584385463s\n",
                        "Trial 8 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.8562715947628021s\n",
                        "Trial 9 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.8520763715108236s\n",
                        "Trial 10 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.8323745250701904s\n",
                        "Accuracies: [('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0)]\n",
                        "Times: [('exact_trace', 1.404020071029663), ('exact_trace', 1.1388757228851318), ('exact_trace', 0.9810603459676107), ('exact_trace', 0.9242104291915894), ('exact_trace', 0.875962209701538), ('exact_trace', 0.8502724170684814), ('exact_trace', 0.8630331584385463), ('exact_trace', 0.8562715947628021), ('exact_trace', 0.8520763715108236), ('exact_trace', 0.8323745250701904)]\n"
                    ]
                }
            ],
            "source": [
                "#Regular Testing Function\n",
                "def testing_graph_methods_regular(graph, accuracies, times,algo):\n",
                " \n",
                "    exact_netx_result = exact_netx(graph)\n",
                "    exact_triangles = exact_netx_result['triangles']\n",
                "    print(f\"Exact NetworkX Triangles: {exact_triangles}, Time: {exact_netx_result['time']}s\")\n",
                " \n",
                "    total_nodes = len(graph.nodes())\n",
                "    algo_name=algo.__name__\n",
                " \n",
                "# create for loop for trials\n",
                "    method_accuracies = []\n",
                "    method_times = []\n",
                "    # Run 10 trials for the current method\n",
                "    for trial in range(1, 11):\n",
                "        print(f\"Trial {trial} for {algo_name}\")\n",
                "        result = algo(graph)\n",
                "        rel_error = abs(exact_triangles - result['triangles']) / exact_triangles\n",
                "        method_accuracies.append(rel_error)\n",
                "        method_times.append(result['time'])\n",
                "        avg_acc = sum(method_accuracies) / len(method_accuracies)\n",
                "        accuracies.append((algo_name, avg_acc))\n",
                "        avg_time = sum(method_times) / len(method_times)\n",
                "        times.append((algo_name, avg_time))\n",
                "        print(f\"{algo_name} with average accuracy: {avg_acc}, average time: {avg_time}s\")\n",
                " \n",
                " \n",
                "accuracies = []\n",
                "times = []\n",
                " \n",
                "fb_graph = nx.read_edgelist('facebook_combined.txt', create_using=nx.Graph(), nodetype=int)\n",
                " \n",
                "testing_graph_methods_regular(fb_graph, accuracies, times,exact_trace)\n",
                " \n",
                "print(\"Accuracies:\", accuracies)\n",
                "print(\"Times:\", times)\n",
                "with open('output.csv', 'a', newline='') as csvfile:\n",
                "    writer = csv.writer(csvfile)\n",
                "    writer.writerows(accuracies)\n",
                "    writer.writerow(\"\\n\")\n",
                "    writer.writerows(times)\n",
                "    writer.writerow(\"\\n\")\n",
                "\n"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
