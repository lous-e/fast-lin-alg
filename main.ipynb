{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "id": "KmnOPlm1_Zdd"
            },
            "outputs": [],
            "source": [
                "import networkx as nx\n",
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import random\n",
                "import time\n",
                "import csv"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "id": "7_A_3AvUxW08"
            },
            "outputs": [],
            "source": [
                "def exact_netx(graph):\n",
                "  start = time.time()\n",
                "  t = sum(nx.triangles(graph).values())/3\n",
                "  end = time.time()\n",
                "  return {\"triangles\": t, \"time\": end - start}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "id": "huHhqhPQN86t"
            },
            "outputs": [],
            "source": [
                "def exact_trace(graph):\n",
                "  start = time.time()\n",
                "  adj_matrix = nx.adjacency_matrix(graph, dtype = np.float64)\n",
                "  adj_matrix_cubed = adj_matrix @ adj_matrix @ adj_matrix\n",
                "  t = adj_matrix_cubed.trace()/6\n",
                "  end = time.time()\n",
                "  return {\"triangles\": t, \"time\": end - start}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "id": "FtTYYA63qt6P"
            },
            "outputs": [],
            "source": [
                "def uniform_sampling(graph, sample_size):\n",
                "  start = time.time()\n",
                "  nodes = list(graph.nodes)\n",
                "  n = len(nodes)\n",
                "  node_sample = random.sample(nodes, sample_size)\n",
                "  sample_t = 0\n",
                "  for node in node_sample:\n",
                "    sample_t += nx.triangles(graph, node)\n",
                "  sample_t /= 3\n",
                "  t = sample_t*n/sample_size\n",
                "  end = time.time()\n",
                "  return {\"triangles\": t, \"time\": end - start}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "id": "NCJYKqJxChh5"
            },
            "outputs": [],
            "source": [
                "def random_sampling_with_degrees(graph, sample_size):\n",
                "  start = time.time()\n",
                "  nodes = []\n",
                "  degrees = []\n",
                "  sum_of_degrees=0\n",
                "  for node in graph:\n",
                "    nodes.append(node)\n",
                "    degree=graph.degree(node)\n",
                "    degrees.append(degree)\n",
                "    sum_of_degrees+=degree\n",
                "  node_sample = random.choices(nodes, weights = degrees, k = sample_size)\n",
                "  sample_t = 0\n",
                "  for node in node_sample:\n",
                "    sample_t += nx.triangles(graph, node)/graph.degree(node)\n",
                "  t = sample_t*sum_of_degrees/3\n",
                "  end = time.time()\n",
                "  return {\"triangles\": t, \"time\": end - start}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "def hutchplusplus(graph, queries):\n",
                "    start = time.time()\n",
                "    A = nx.adjacency_matrix(graph, dtype = np.float64)\n",
                "    d = A.shape[0]\n",
                "    S = np.random.choice([1, -1], size = (d, queries//3))\n",
                "    G = np.random.choice([1, -1], size = (d, queries//3))\n",
                "    Q, R = np.linalg.qr(A @ (A @ (A @ S)))\n",
                "    term_1 = np.trace(Q.T @ (A @ (A @ (A @ Q))))\n",
                "    term_prod = G - Q @ (Q.T @ G)\n",
                "    term_2 = 3/queries*np.trace(term_prod.T @ (A @ (A @ (A @ term_prod))))\n",
                "    t = term_1/6 + (term_2 - term_1)/6\n",
                "    end = time.time()\n",
                "    return {\"triangles\": t, \"time\": end - start}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "# def lanczos(A, m):\n",
                "#     n = A.shape[0]\n",
                "#     v = [np.random.rand(n)]\n",
                "#     w_prime = [A @ v[0]]\n",
                "#     alpha = [w_prime[0] * v[0]]\n",
                "#     beta = []\n",
                "#     w = [w_prime[0] - alpha[0] @ v[0]]\n",
                "#     for j in range(2, m + 1):\n",
                "#         beta_j = np.linalg.norm(w[-1])\n",
                "#         beta.push(beta_j)\n",
                "#         if beta_j != 0:\n",
                "#             v_j = w[-1]/beta_j\n",
                "#         else:\n",
                "#             v_j = #TODO\n",
                "#         v.push(v_j)\n",
                "#         w_prime.push(A @ v[-1])\n",
                "#         alpha.push(w_prime[-1]*v[-1])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# def eigenTriangle(graph, sample_size, tol):\n",
                "#   adj_matrix = nx.adjacency_matrix(graph, dtype = np.float64)\n",
                "#   nodes = list(graph.nodes)\n",
                "#   n = len(nodes)\n",
                "#   node_sample = random.sample(nodes, sample_size)\n",
                "#   for node in node_sample:\n",
                "#     lambda_1 = lanczos(A, 1)\n",
                "#     eigen = lambda_1\n",
                "#     i = 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Exact NetworkX Triangles: 1612010.0, Time: 0.5042119026184082s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 201\n",
                        "Trial 2 for uniform_sampling with Sample Size: 201\n",
                        "Trial 3 for uniform_sampling with Sample Size: 201\n",
                        "Trial 4 for uniform_sampling with Sample Size: 201\n",
                        "Trial 5 for uniform_sampling with Sample Size: 201\n",
                        "Trial 6 for uniform_sampling with Sample Size: 201\n",
                        "Trial 7 for uniform_sampling with Sample Size: 201\n",
                        "Trial 8 for uniform_sampling with Sample Size: 201\n",
                        "Trial 9 for uniform_sampling with Sample Size: 201\n",
                        "Trial 10 for uniform_sampling with Sample Size: 201\n",
                        "uniform_sampling with sample size: 201: average accuracy: 0.15377777728397196, average time: 0.13070342540740967s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 403\n",
                        "Trial 2 for uniform_sampling with Sample Size: 403\n",
                        "Trial 3 for uniform_sampling with Sample Size: 403\n",
                        "Trial 4 for uniform_sampling with Sample Size: 403\n",
                        "Trial 5 for uniform_sampling with Sample Size: 403\n",
                        "Trial 6 for uniform_sampling with Sample Size: 403\n",
                        "Trial 7 for uniform_sampling with Sample Size: 403\n",
                        "Trial 8 for uniform_sampling with Sample Size: 403\n",
                        "Trial 9 for uniform_sampling with Sample Size: 403\n",
                        "Trial 10 for uniform_sampling with Sample Size: 403\n",
                        "uniform_sampling with sample size: 403: average accuracy: 0.0732869192189404, average time: 0.23476274013519288s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 605\n",
                        "Trial 2 for uniform_sampling with Sample Size: 605\n",
                        "Trial 3 for uniform_sampling with Sample Size: 605\n",
                        "Trial 4 for uniform_sampling with Sample Size: 605\n",
                        "Trial 5 for uniform_sampling with Sample Size: 605\n",
                        "Trial 6 for uniform_sampling with Sample Size: 605\n",
                        "Trial 7 for uniform_sampling with Sample Size: 605\n",
                        "Trial 8 for uniform_sampling with Sample Size: 605\n",
                        "Trial 9 for uniform_sampling with Sample Size: 605\n",
                        "Trial 10 for uniform_sampling with Sample Size: 605\n",
                        "uniform_sampling with sample size: 605: average accuracy: 0.1149809242308804, average time: 0.3405918598175049s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 807\n",
                        "Trial 2 for uniform_sampling with Sample Size: 807\n",
                        "Trial 3 for uniform_sampling with Sample Size: 807\n",
                        "Trial 4 for uniform_sampling with Sample Size: 807\n",
                        "Trial 5 for uniform_sampling with Sample Size: 807\n",
                        "Trial 6 for uniform_sampling with Sample Size: 807\n",
                        "Trial 7 for uniform_sampling with Sample Size: 807\n",
                        "Trial 8 for uniform_sampling with Sample Size: 807\n",
                        "Trial 9 for uniform_sampling with Sample Size: 807\n",
                        "Trial 10 for uniform_sampling with Sample Size: 807\n",
                        "uniform_sampling with sample size: 807: average accuracy: 0.07583781453394005, average time: 0.4833421468734741s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 2 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 3 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 4 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 5 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 6 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 7 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 8 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 9 for uniform_sampling with Sample Size: 1009\n",
                        "Trial 10 for uniform_sampling with Sample Size: 1009\n",
                        "uniform_sampling with sample size: 1009: average accuracy: 0.04965402555098543, average time: 0.6047505378723145s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 2 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 3 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 4 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 5 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 6 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 7 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 8 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 9 for uniform_sampling with Sample Size: 1211\n",
                        "Trial 10 for uniform_sampling with Sample Size: 1211\n",
                        "uniform_sampling with sample size: 1211: average accuracy: 0.05213484059842283, average time: 0.7363017797470093s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 2 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 3 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 4 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 5 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 6 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 7 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 8 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 9 for uniform_sampling with Sample Size: 1413\n",
                        "Trial 10 for uniform_sampling with Sample Size: 1413\n",
                        "uniform_sampling with sample size: 1413: average accuracy: 0.04148002695952467, average time: 0.8551384687423706s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 2 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 3 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 4 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 5 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 6 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 7 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 8 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 9 for uniform_sampling with Sample Size: 1615\n",
                        "Trial 10 for uniform_sampling with Sample Size: 1615\n",
                        "uniform_sampling with sample size: 1615: average accuracy: 0.02899736544769289, average time: 0.9597981691360473s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 2 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 3 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 4 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 5 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 6 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 7 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 8 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 9 for uniform_sampling with Sample Size: 1817\n",
                        "Trial 10 for uniform_sampling with Sample Size: 1817\n",
                        "uniform_sampling with sample size: 1817: average accuracy: 0.03291839908925417, average time: 1.0543272495269775s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 2 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 3 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 4 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 5 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 6 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 7 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 8 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 9 for uniform_sampling with Sample Size: 2019\n",
                        "Trial 10 for uniform_sampling with Sample Size: 2019\n",
                        "uniform_sampling with sample size: 2019: average accuracy: 0.028022107350001064, average time: 1.1817489385604858s\n",
                        "Exact NetworkX Triangles: 727044.0, Time: 0.9452378749847412s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 1834\n",
                        "Trial 2 for uniform_sampling with Sample Size: 1834\n",
                        "Trial 3 for uniform_sampling with Sample Size: 1834\n",
                        "Trial 4 for uniform_sampling with Sample Size: 1834\n",
                        "Trial 5 for uniform_sampling with Sample Size: 1834\n",
                        "Trial 6 for uniform_sampling with Sample Size: 1834\n",
                        "Trial 7 for uniform_sampling with Sample Size: 1834\n",
                        "Trial 8 for uniform_sampling with Sample Size: 1834\n",
                        "Trial 9 for uniform_sampling with Sample Size: 1834\n",
                        "Trial 10 for uniform_sampling with Sample Size: 1834\n",
                        "uniform_sampling with sample size: 1834: average accuracy: 0.09520385671653603, average time: 0.2892191171646118s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 3669\n",
                        "Trial 2 for uniform_sampling with Sample Size: 3669\n",
                        "Trial 3 for uniform_sampling with Sample Size: 3669\n",
                        "Trial 4 for uniform_sampling with Sample Size: 3669\n",
                        "Trial 5 for uniform_sampling with Sample Size: 3669\n",
                        "Trial 6 for uniform_sampling with Sample Size: 3669\n",
                        "Trial 7 for uniform_sampling with Sample Size: 3669\n",
                        "Trial 8 for uniform_sampling with Sample Size: 3669\n",
                        "Trial 9 for uniform_sampling with Sample Size: 3669\n",
                        "Trial 10 for uniform_sampling with Sample Size: 3669\n",
                        "uniform_sampling with sample size: 3669: average accuracy: 0.0890862340601504, average time: 0.5571608066558837s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 5503\n",
                        "Trial 2 for uniform_sampling with Sample Size: 5503\n",
                        "Trial 3 for uniform_sampling with Sample Size: 5503\n",
                        "Trial 4 for uniform_sampling with Sample Size: 5503\n",
                        "Trial 5 for uniform_sampling with Sample Size: 5503\n",
                        "Trial 6 for uniform_sampling with Sample Size: 5503\n",
                        "Trial 7 for uniform_sampling with Sample Size: 5503\n",
                        "Trial 8 for uniform_sampling with Sample Size: 5503\n",
                        "Trial 9 for uniform_sampling with Sample Size: 5503\n",
                        "Trial 10 for uniform_sampling with Sample Size: 5503\n",
                        "uniform_sampling with sample size: 5503: average accuracy: 0.0757884937707087, average time: 0.9094594478607178s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 7338\n",
                        "Trial 2 for uniform_sampling with Sample Size: 7338\n",
                        "Trial 3 for uniform_sampling with Sample Size: 7338\n",
                        "Trial 4 for uniform_sampling with Sample Size: 7338\n",
                        "Trial 5 for uniform_sampling with Sample Size: 7338\n",
                        "Trial 6 for uniform_sampling with Sample Size: 7338\n",
                        "Trial 7 for uniform_sampling with Sample Size: 7338\n",
                        "Trial 8 for uniform_sampling with Sample Size: 7338\n",
                        "Trial 9 for uniform_sampling with Sample Size: 7338\n",
                        "Trial 10 for uniform_sampling with Sample Size: 7338\n",
                        "uniform_sampling with sample size: 7338: average accuracy: 0.06005746668006656, average time: 1.117495584487915s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 9173\n",
                        "Trial 2 for uniform_sampling with Sample Size: 9173\n",
                        "Trial 3 for uniform_sampling with Sample Size: 9173\n",
                        "Trial 4 for uniform_sampling with Sample Size: 9173\n",
                        "Trial 5 for uniform_sampling with Sample Size: 9173\n",
                        "Trial 6 for uniform_sampling with Sample Size: 9173\n",
                        "Trial 7 for uniform_sampling with Sample Size: 9173\n",
                        "Trial 8 for uniform_sampling with Sample Size: 9173\n",
                        "Trial 9 for uniform_sampling with Sample Size: 9173\n",
                        "Trial 10 for uniform_sampling with Sample Size: 9173\n",
                        "uniform_sampling with sample size: 9173: average accuracy: 0.04079422978526746, average time: 1.418119692802429s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 11007\n",
                        "Trial 2 for uniform_sampling with Sample Size: 11007\n",
                        "Trial 3 for uniform_sampling with Sample Size: 11007\n",
                        "Trial 4 for uniform_sampling with Sample Size: 11007\n",
                        "Trial 5 for uniform_sampling with Sample Size: 11007\n",
                        "Trial 6 for uniform_sampling with Sample Size: 11007\n",
                        "Trial 7 for uniform_sampling with Sample Size: 11007\n",
                        "Trial 8 for uniform_sampling with Sample Size: 11007\n",
                        "Trial 9 for uniform_sampling with Sample Size: 11007\n",
                        "Trial 10 for uniform_sampling with Sample Size: 11007\n",
                        "uniform_sampling with sample size: 11007: average accuracy: 0.04021532711379359, average time: 1.7074794054031373s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 12842\n",
                        "Trial 2 for uniform_sampling with Sample Size: 12842\n",
                        "Trial 3 for uniform_sampling with Sample Size: 12842\n",
                        "Trial 4 for uniform_sampling with Sample Size: 12842\n",
                        "Trial 5 for uniform_sampling with Sample Size: 12842\n",
                        "Trial 6 for uniform_sampling with Sample Size: 12842\n",
                        "Trial 7 for uniform_sampling with Sample Size: 12842\n",
                        "Trial 8 for uniform_sampling with Sample Size: 12842\n",
                        "Trial 9 for uniform_sampling with Sample Size: 12842\n",
                        "Trial 10 for uniform_sampling with Sample Size: 12842\n",
                        "uniform_sampling with sample size: 12842: average accuracy: 0.043167903138065636, average time: 2.0339317321777344s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 14676\n",
                        "Trial 2 for uniform_sampling with Sample Size: 14676\n",
                        "Trial 3 for uniform_sampling with Sample Size: 14676\n",
                        "Trial 4 for uniform_sampling with Sample Size: 14676\n",
                        "Trial 5 for uniform_sampling with Sample Size: 14676\n",
                        "Trial 6 for uniform_sampling with Sample Size: 14676\n",
                        "Trial 7 for uniform_sampling with Sample Size: 14676\n",
                        "Trial 8 for uniform_sampling with Sample Size: 14676\n",
                        "Trial 9 for uniform_sampling with Sample Size: 14676\n",
                        "Trial 10 for uniform_sampling with Sample Size: 14676\n",
                        "uniform_sampling with sample size: 14676: average accuracy: 0.03193928529770364, average time: 2.3009793519973756s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 16511\n",
                        "Trial 2 for uniform_sampling with Sample Size: 16511\n",
                        "Trial 3 for uniform_sampling with Sample Size: 16511\n",
                        "Trial 4 for uniform_sampling with Sample Size: 16511\n",
                        "Trial 5 for uniform_sampling with Sample Size: 16511\n",
                        "Trial 6 for uniform_sampling with Sample Size: 16511\n",
                        "Trial 7 for uniform_sampling with Sample Size: 16511\n",
                        "Trial 8 for uniform_sampling with Sample Size: 16511\n",
                        "Trial 9 for uniform_sampling with Sample Size: 16511\n",
                        "Trial 10 for uniform_sampling with Sample Size: 16511\n",
                        "uniform_sampling with sample size: 16511: average accuracy: 0.03451884381795303, average time: 2.560198450088501s\n",
                        "Trial 1 for uniform_sampling with Sample Size: 18346\n",
                        "Trial 2 for uniform_sampling with Sample Size: 18346\n",
                        "Trial 3 for uniform_sampling with Sample Size: 18346\n",
                        "Trial 4 for uniform_sampling with Sample Size: 18346\n",
                        "Trial 5 for uniform_sampling with Sample Size: 18346\n",
                        "Trial 6 for uniform_sampling with Sample Size: 18346\n",
                        "Trial 7 for uniform_sampling with Sample Size: 18346\n",
                        "Trial 8 for uniform_sampling with Sample Size: 18346\n",
                        "Trial 9 for uniform_sampling with Sample Size: 18346\n",
                        "Trial 10 for uniform_sampling with Sample Size: 18346\n",
                        "uniform_sampling with sample size: 18346: average accuracy: 0.0218931270551255, average time: 2.9646605968475344s\n",
                        "Accuracies: [('uniform_sampling', 201, 0.002463878027990267), ('uniform_sampling', 201, 0.17468113647308028), ('uniform_sampling', 201, 0.1602025380870962), ('uniform_sampling', 201, 0.2062740026272321), ('uniform_sampling', 201, 0.19749349109935094), ('uniform_sampling', 201, 0.17584190589646279), ('uniform_sampling', 201, 0.16254247933232738), ('uniform_sampling', 201, 0.17394677908114733), ('uniform_sampling', 201, 0.15859630335806227), ('uniform_sampling', 201, 0.15377777728397196), ('uniform_sampling', 403, 0.03695266643795538), ('uniform_sampling', 403, 0.06085586377222886), ('uniform_sampling', 403, 0.06379449999238641), ('uniform_sampling', 403, 0.05542402536370802), ('uniform_sampling', 403, 0.06576540837033504), ('uniform_sampling', 403, 0.06433098307962613), ('uniform_sampling', 403, 0.07787883149468401), ('uniform_sampling', 403, 0.07002797168302581), ('uniform_sampling', 403, 0.07110957849026596), ('uniform_sampling', 403, 0.0732869192189404), ('uniform_sampling', 605, 0.09324406470077237), ('uniform_sampling', 605, 0.06255912185876529), ('uniform_sampling', 605, 0.09752238091567139), ('uniform_sampling', 605, 0.10341834876749788), ('uniform_sampling', 605, 0.11964611160889553), ('uniform_sampling', 605, 0.10935273992386206), ('uniform_sampling', 605, 0.12167194597090421), ('uniform_sampling', 605, 0.10978148958259476), ('uniform_sampling', 605, 0.11799832602942893), ('uniform_sampling', 605, 0.1149809242308804), ('uniform_sampling', 807, 0.03325867558969233), ('uniform_sampling', 807, 0.022055411304541694), ('uniform_sampling', 807, 0.03630817991944049), ('uniform_sampling', 807, 0.05971240514467381), ('uniform_sampling', 807, 0.059131160409538586), ('uniform_sampling', 807, 0.0657529055768973), ('uniform_sampling', 807, 0.0574896102970765), ('uniform_sampling', 807, 0.05121387219182092), ('uniform_sampling', 807, 0.05563849576385376), ('uniform_sampling', 807, 0.07583781453394005), ('uniform_sampling', 1009, 0.0501531524107836), ('uniform_sampling', 1009, 0.04172841948943014), ('uniform_sampling', 1009, 0.055839171282885784), ('uniform_sampling', 1009, 0.06499100454722478), ('uniform_sampling', 1009, 0.05698647352066445), ('uniform_sampling', 1009, 0.047934672593227125), ('uniform_sampling', 1009, 0.04407482456969815), ('uniform_sampling', 1009, 0.038805671178650525), ('uniform_sampling', 1009, 0.040783784722387965), ('uniform_sampling', 1009, 0.04965402555098543), ('uniform_sampling', 1211, 0.0443575349909319), ('uniform_sampling', 1211, 0.04748587370768785), ('uniform_sampling', 1211, 0.057641648585963136), ('uniform_sampling', 1211, 0.054133892297531266), ('uniform_sampling', 1211, 0.07091775596423566), ('uniform_sampling', 1211, 0.061816445109793776), ('uniform_sampling', 1211, 0.05414299920716407), ('uniform_sampling', 1211, 0.04755580608749217), ('uniform_sampling', 1211, 0.053833199124112094), ('uniform_sampling', 1211, 0.05213484059842283), ('uniform_sampling', 1413, 0.030511437370840697), ('uniform_sampling', 1413, 0.03241913243457984), ('uniform_sampling', 1413, 0.0236391116624418), ('uniform_sampling', 1413, 0.05183883773498546), ('uniform_sampling', 1413, 0.04763270160774888), ('uniform_sampling', 1413, 0.04539432234103449), ('uniform_sampling', 1413, 0.04059662065406133), ('uniform_sampling', 1413, 0.04011970393605962), ('uniform_sampling', 1413, 0.043109950419083956), ('uniform_sampling', 1413, 0.04148002695952467), ('uniform_sampling', 1615, 0.03471728918397611), ('uniform_sampling', 1615, 0.03470586033042526), ('uniform_sampling', 1615, 0.028414636098398765), ('uniform_sampling', 1615, 0.02186116763930327), ('uniform_sampling', 1615, 0.020678519069536678), ('uniform_sampling', 1615, 0.021988678369640805), ('uniform_sampling', 1615, 0.029590638641101848), ('uniform_sampling', 1615, 0.02960693979797633), ('uniform_sampling', 1615, 0.02922200290257473), ('uniform_sampling', 1615, 0.02899736544769289), ('uniform_sampling', 1817, 0.041541599643588015), ('uniform_sampling', 1817, 0.026096559669718505), ('uniform_sampling', 1817, 0.029329675955000033), ('uniform_sampling', 1817, 0.027421049303062547), ('uniform_sampling', 1817, 0.03429349957202042), ('uniform_sampling', 1817, 0.045852356628325264), ('uniform_sampling', 1817, 0.04027319854016413), ('uniform_sampling', 1817, 0.037351611214787535), ('uniform_sampling', 1817, 0.03483912244919504), ('uniform_sampling', 1817, 0.03291839908925417), ('uniform_sampling', 2019, 0.08887808454652059), ('uniform_sampling', 2019, 0.05879707108988643), ('uniform_sampling', 2019, 0.04178147589244935), ('uniform_sampling', 2019, 0.0386873092930719), ('uniform_sampling', 2019, 0.03502292877109195), ('uniform_sampling', 2019, 0.03442879122844781), ('uniform_sampling', 2019, 0.03324257463936599), ('uniform_sampling', 2019, 0.03011719193168259), ('uniform_sampling', 2019, 0.0290732648024445), ('uniform_sampling', 2019, 0.028022107350001064), ('uniform_sampling', 1834, 0.2251304646543617), ('uniform_sampling', 1834, 0.12834691067774479), ('uniform_sampling', 1834, 0.1197356183205187), ('uniform_sampling', 1834, 0.10003354090575771), ('uniform_sampling', 1834, 0.10167233921858683), ('uniform_sampling', 1834, 0.1006274635404823), ('uniform_sampling', 1834, 0.09240287451199995), ('uniform_sampling', 1834, 0.08598119377991852), ('uniform_sampling', 1834, 0.10440101672002501), ('uniform_sampling', 1834, 0.09520385671653603), ('uniform_sampling', 3669, 0.15000052480618886), ('uniform_sampling', 3669, 0.17164642860901108), ('uniform_sampling', 3669, 0.15632996518957556), ('uniform_sampling', 3669, 0.14533498141620518), ('uniform_sampling', 3669, 0.13198023467578332), ('uniform_sampling', 3669, 0.1215387942393925), ('uniform_sampling', 3669, 0.10876788834034881), ('uniform_sampling', 3669, 0.10018637876125532), ('uniform_sampling', 3669, 0.09250590544890486), ('uniform_sampling', 3669, 0.0890862340601504), ('uniform_sampling', 5503, 0.019267278772936262), ('uniform_sampling', 5503, 0.03392235063148759), ('uniform_sampling', 5503, 0.055671610383185376), ('uniform_sampling', 5503, 0.07795595734029713), ('uniform_sampling', 5503, 0.08273803980029407), ('uniform_sampling', 5503, 0.0699649306722935), ('uniform_sampling', 5503, 0.07381982830523084), ('uniform_sampling', 5503, 0.08503721264861991), ('uniform_sampling', 5503, 0.08053709122329095), ('uniform_sampling', 5503, 0.0757884937707087), ('uniform_sampling', 7338, 0.035525640947992994), ('uniform_sampling', 7338, 0.06892324453293225), ('uniform_sampling', 7338, 0.0728022692505983), ('uniform_sampling', 7338, 0.06355718584814996), ('uniform_sampling', 7338, 0.054304406354586575), ('uniform_sampling', 7338, 0.054857627012026955), ('uniform_sampling', 7338, 0.0531288553864254), ('uniform_sampling', 7338, 0.06071554643108056), ('uniform_sampling', 7338, 0.06115197503056865), ('uniform_sampling', 7338, 0.06005746668006656), ('uniform_sampling', 9173, 0.09663789261722812), ('uniform_sampling', 9173, 0.06620873931518131), ('uniform_sampling', 9173, 0.06193114401145827), ('uniform_sampling', 9173, 0.055980564220780786), ('uniform_sampling', 9173, 0.05676721995734326), ('uniform_sampling', 9173, 0.05101571110781008), ('uniform_sampling', 9173, 0.04560148452402567), ('uniform_sampling', 9173, 0.04192456027420624), ('uniform_sampling', 9173, 0.04268772158473469), ('uniform_sampling', 9173, 0.04079422978526746), ('uniform_sampling', 11007, 0.05477108047588869), ('uniform_sampling', 11007, 0.04850793610082935), ('uniform_sampling', 11007, 0.04729188553768742), ('uniform_sampling', 11007, 0.04781024810492533), ('uniform_sampling', 11007, 0.04668645843704315), ('uniform_sampling', 11007, 0.04479737712443885), ('uniform_sampling', 11007, 0.04130355155980472), ('uniform_sampling', 11007, 0.0428801997965194), ('uniform_sampling', 11007, 0.044473963034576604), ('uniform_sampling', 11007, 0.04021532711379359), ('uniform_sampling', 12842, 0.023768252590391566), ('uniform_sampling', 12842, 0.036032062395620484), ('uniform_sampling', 12842, 0.041254421053689906), ('uniform_sampling', 12842, 0.03583602016228694), ('uniform_sampling', 12842, 0.029602471385131036), ('uniform_sampling', 12842, 0.03155938194199934), ('uniform_sampling', 12842, 0.03237281829053188), ('uniform_sampling', 12842, 0.03642005683720098), ('uniform_sampling', 12842, 0.04141096241247655), ('uniform_sampling', 12842, 0.043167903138065636), ('uniform_sampling', 14676, 0.022186656487420957), ('uniform_sampling', 14676, 0.02021709533585448), ('uniform_sampling', 14676, 0.029724429485976093), ('uniform_sampling', 14676, 0.023632792661947604), ('uniform_sampling', 14676, 0.023799658293614488), ('uniform_sampling', 14676, 0.020727175199280298), ('uniform_sampling', 14676, 0.028612642160949695), ('uniform_sampling', 14676, 0.03309320560803291), ('uniform_sampling', 14676, 0.0304764386892859), ('uniform_sampling', 14676, 0.03193928529770364), ('uniform_sampling', 16511, 0.031029876595500966), ('uniform_sampling', 16511, 0.016728212444088425), ('uniform_sampling', 16511, 0.02924423132511259), ('uniform_sampling', 16511, 0.03019886315982999), ('uniform_sampling', 16511, 0.02654616120385231), ('uniform_sampling', 16511, 0.026936886355770375), ('uniform_sampling', 16511, 0.02986807776857186), ('uniform_sampling', 16511, 0.02985961271417686), ('uniform_sampling', 16511, 0.031014080488384665), ('uniform_sampling', 16511, 0.03451884381795303), ('uniform_sampling', 18346, 0.05499254515545139), ('uniform_sampling', 18346, 0.029470935275810937), ('uniform_sampling', 18346, 0.046049788213948874), ('uniform_sampling', 18346, 0.039327972814116735), ('uniform_sampling', 18346, 0.03342117762703038), ('uniform_sampling', 18346, 0.02974495200962926), ('uniform_sampling', 18346, 0.02905699556796327), ('uniform_sampling', 18346, 0.025445617229952148), ('uniform_sampling', 18346, 0.023694220350818848), ('uniform_sampling', 18346, 0.0218931270551255)]\n",
                        "Times: [('uniform_sampling', 201, 0.13070342540740967), ('uniform_sampling', 403, 0.23476274013519288), ('uniform_sampling', 605, 0.3405918598175049), ('uniform_sampling', 807, 0.4833421468734741), ('uniform_sampling', 1009, 0.6047505378723145), ('uniform_sampling', 1211, 0.7363017797470093), ('uniform_sampling', 1413, 0.8551384687423706), ('uniform_sampling', 1615, 0.9597981691360473), ('uniform_sampling', 1817, 1.0543272495269775), ('uniform_sampling', 2019, 1.1817489385604858), ('uniform_sampling', 1834, 0.2892191171646118), ('uniform_sampling', 3669, 0.5571608066558837), ('uniform_sampling', 5503, 0.9094594478607178), ('uniform_sampling', 7338, 1.117495584487915), ('uniform_sampling', 9173, 1.418119692802429), ('uniform_sampling', 11007, 1.7074794054031373), ('uniform_sampling', 12842, 2.0339317321777344), ('uniform_sampling', 14676, 2.3009793519973756), ('uniform_sampling', 16511, 2.560198450088501), ('uniform_sampling', 18346, 2.9646605968475344)]\n"
                    ]
                }
            ],
            "source": [
                "# Sampling Testing Function\n",
                "def testing_graph_methods_sampling(graph, accuracies, times,algo):\n",
                " \n",
                "    exact_netx_result = exact_netx(graph)\n",
                "    exact_triangles = exact_netx_result['triangles']\n",
                "    print(f\"Exact NetworkX Triangles: {exact_triangles}, Time: {exact_netx_result['time']}s\")\n",
                " \n",
                "    total_nodes = len(graph.nodes())\n",
                "    sample_sizes = [int(total_nodes * percentage / 100) for percentage in range(5,55,5) ]\n",
                "    algo_name=algo.__name__\n",
                " \n",
                "# create for loop for trials and another for loop for sample size according to sampling; between 5% and 50% in increments of 5% f the sample size given.\n",
                "    # evaluate each method with respective names according to the methods being used\n",
                "    for sample_size in sample_sizes:\n",
                "            method_accuracies = []\n",
                "            method_times = []\n",
                " \n",
                "            # Run 10 trials for the current method and sample size\n",
                "            for trial in range(1, 11):\n",
                "                print(f\"Trial {trial} for {algo_name} with Sample Size: {sample_size}\")\n",
                "                \n",
                "                result = algo(graph, sample_size)\n",
                "                rel_error = abs(exact_triangles - result['triangles']) / exact_triangles\n",
                "                method_accuracies.append(rel_error)\n",
                " \n",
                "                method_times.append(result['time'])\n",
                "                avg_acc = sum(method_accuracies) / len(method_accuracies)\n",
                "                accuracies.append((algo_name, sample_size, avg_acc))\n",
                "            avg_time = sum(method_times) / len(method_times)\n",
                "            times.append((algo_name, sample_size, avg_time))\n",
                "            print(f\"{algo_name} with sample size: {sample_size}: average accuracy: {avg_acc}, average time: {avg_time}s\")\n",
                " \n",
                "accuracies = []\n",
                "times = []\n",
                " \n",
                "fb_graph = nx.read_edgelist('facebook_combined.txt', create_using=nx.Graph(), nodetype=int)\n",
                "email_graph = nx.read_edgelist('email-Enron.txt', create_using=nx.Graph(), nodetype=int)\n",
                " \n",
                "testing_graph_methods_sampling(fb_graph, accuracies, times,uniform_sampling)\n",
                "testing_graph_methods_sampling(email_graph, accuracies, times,uniform_sampling)\n",
                " \n",
                "print(\"Accuracies:\", accuracies)\n",
                "print(\"Times:\", times)\n",
                "with open('output.csv', 'a', newline='') as csvfile:\n",
                "    writer = csv.writer(csvfile)\n",
                "    writer.writerows(accuracies)\n",
                "    writer.writerow(\"\\n\")\n",
                "    writer.writerows(times)\n",
                "    writer.writerow(\"\\n\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Exact NetworkX Triangles: 1612010.0, Time: 0.48077869415283203s\n",
                        "Trial 1 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 1.404020071029663s\n",
                        "Trial 2 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 1.1388757228851318s\n",
                        "Trial 3 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.9810603459676107s\n",
                        "Trial 4 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.9242104291915894s\n",
                        "Trial 5 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.875962209701538s\n",
                        "Trial 6 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.8502724170684814s\n",
                        "Trial 7 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.8630331584385463s\n",
                        "Trial 8 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.8562715947628021s\n",
                        "Trial 9 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.8520763715108236s\n",
                        "Trial 10 for exact_trace\n",
                        "exact_trace with average accuracy: 0.0, average time: 0.8323745250701904s\n",
                        "Accuracies: [('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0), ('exact_trace', 0.0)]\n",
                        "Times: [('exact_trace', 1.404020071029663), ('exact_trace', 1.1388757228851318), ('exact_trace', 0.9810603459676107), ('exact_trace', 0.9242104291915894), ('exact_trace', 0.875962209701538), ('exact_trace', 0.8502724170684814), ('exact_trace', 0.8630331584385463), ('exact_trace', 0.8562715947628021), ('exact_trace', 0.8520763715108236), ('exact_trace', 0.8323745250701904)]\n"
                    ]
                }
            ],
            "source": [
                "#Regular Testing Function\n",
                "def testing_graph_methods_regular(graph, accuracies, times,algo):\n",
                " \n",
                "    exact_netx_result = exact_netx(graph)\n",
                "    exact_triangles = exact_netx_result['triangles']\n",
                "    print(f\"Exact NetworkX Triangles: {exact_triangles}, Time: {exact_netx_result['time']}s\")\n",
                " \n",
                "    total_nodes = len(graph.nodes())\n",
                "    algo_name=algo.__name__\n",
                " \n",
                "# create for loop for trials\n",
                "    method_accuracies = []\n",
                "    method_times = []\n",
                "    # Run 10 trials for the current method\n",
                "    for trial in range(1, 11):\n",
                "        print(f\"Trial {trial} for {algo_name}\")\n",
                "        result = algo(graph)\n",
                "        rel_error = abs(exact_triangles - result['triangles']) / exact_triangles\n",
                "        method_accuracies.append(rel_error)\n",
                "        method_times.append(result['time'])\n",
                "        avg_acc = sum(method_accuracies) / len(method_accuracies)\n",
                "        accuracies.append((algo_name, avg_acc))\n",
                "        avg_time = sum(method_times) / len(method_times)\n",
                "        times.append((algo_name, avg_time))\n",
                "        print(f\"{algo_name} with average accuracy: {avg_acc}, average time: {avg_time}s\")\n",
                " \n",
                " \n",
                "accuracies = []\n",
                "times = []\n",
                " \n",
                "fb_graph = nx.read_edgelist('facebook_combined.txt', create_using=nx.Graph(), nodetype=int)\n",
                " \n",
                "testing_graph_methods_regular(fb_graph, accuracies, times,exact_trace)\n",
                " \n",
                "print(\"Accuracies:\", accuracies)\n",
                "print(\"Times:\", times)\n",
                "with open('output.csv', 'a', newline='') as csvfile:\n",
                "    writer = csv.writer(csvfile)\n",
                "    writer.writerows(accuracies)\n",
                "    writer.writerow(\"\\n\")\n",
                "    writer.writerows(times)\n",
                "    writer.writerow(\"\\n\")\n",
                "\n"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
